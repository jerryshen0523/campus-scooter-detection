#!/usr/bin/env python3
"""
Haar Cascade Training Script for Scooter Detection
æ»‘æ¿è»ŠHaarç´šè¯åˆ†é¡å™¨è¨“ç·´è…³æœ¬

æ­¤è…³æœ¬è‡ªå‹•åŒ–Haar cascadeè¨“ç·´éç¨‹
"""

import os
import subprocess
import argparse
import shutil
import stat
import time
from pathlib import Path
import cv2
import numpy as np
from tqdm import tqdm

class HaarCascadeTrainer:
    def __init__(self, project_dir="./"):
        """
        åˆå§‹åŒ–Haar cascadeè¨“ç·´å™¨

        Args:
            project_dir (str): å°ˆæ¡ˆç›®éŒ„è·¯å¾‘
        """
        self.project_dir = Path(project_dir).resolve()
        self.data_dir = self.project_dir / "data"
        self.positive_dir = self.data_dir / "positive"
        self.negative_dir = self.data_dir / "negative"
        self.annotations_dir = self.data_dir / "annotations"
        self.output_dir = self.data_dir / "trained_model"

        # å‰µå»ºå¿…è¦ç›®éŒ„
        for dir_path in [self.positive_dir, self.negative_dir, 
                        self.annotations_dir, self.output_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)

        print(f"è¨“ç·´å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"å°ˆæ¡ˆç›®éŒ„: {self.project_dir}")
        print(f"æ­£æ¨£æœ¬ç›®éŒ„: {self.positive_dir}")
        print(f"è² æ¨£æœ¬ç›®éŒ„: {self.negative_dir}")
        print(f"æ¨™è¨»ç›®éŒ„: {self.annotations_dir}")
        print(f"è¼¸å‡ºç›®éŒ„: {self.output_dir}")

    def prepare_positive_samples(self):
        """
        æº–å‚™æ­£æ¨£æœ¬æè¿°æª”æ¡ˆ
        å¾æ¨™è¨»æª”æ¡ˆç”Ÿæˆæ­£æ¨£æœ¬è³‡è¨Š

        Returns:
            str: æ­£æ¨£æœ¬æè¿°æª”æ¡ˆè·¯å¾‘
        """
        positive_list_file = self.data_dir / "positive_images.txt"

        # ç²å–æ‰€æœ‰æ­£æ¨£æœ¬å½±åƒå’Œå°æ‡‰çš„æ¨™è¨»
        positive_data = []
        invalid_annotations = []
        processed_files = set()  # é˜²æ­¢é‡è¤‡è™•ç†

        for img_ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.JPG', '*.JPEG', '*.PNG', '*.BMP']:
            for img_path in self.positive_dir.glob(img_ext):
                # é˜²æ­¢é‡è¤‡è™•ç†ç›¸åŒæª”æ¡ˆ
                if img_path.name in processed_files:
                    continue
                processed_files.add(img_path.name)
                
                # å°‹æ‰¾å°æ‡‰çš„æ¨™è¨»æª”æ¡ˆ
                annotation_file = self.annotations_dir / f"{img_path.stem}.txt"

                if annotation_file.exists():
                    # å…ˆè®€å–å½±åƒä¾†ç²å–å°ºå¯¸
                    img = cv2.imread(str(img_path))
                    if img is None:
                        print(f"è­¦å‘Š: ç„¡æ³•è®€å–å½±åƒ {img_path}")
                        continue
                    
                    img_height, img_width = img.shape[:2]
                    print(f"è™•ç†å½±åƒ {img_path.name}: {img_width}x{img_height}")
                    
                    # è®€å–æ¨™è¨»è³‡è¨Š
                    annotations = []
                    
                    try:
                        with open(annotation_file, 'r', encoding='utf-8') as f:
                            for line_num, line in enumerate(f, 1):
                                line = line.strip()
                                if line and not line.startswith('#'):
                                    parts = line.split()
                                    if len(parts) >= 5:  # class x y w h (YOLO format)
                                        try:
                                            class_id, x_center, y_center, width, height = map(float, parts[:5])
                                            
                                            # æª¢æŸ¥YOLOæ ¼å¼åº§æ¨™ç¯„åœ
                                            if not (0 <= x_center <= 1 and 0 <= y_center <= 1 and 
                                                   0 < width <= 1 and 0 < height <= 1):
                                                invalid_annotations.append(f"{annotation_file.name}:è¡Œ{line_num} - YOLOåº§æ¨™è¶…å‡ºç¯„åœ")
                                                continue

                                            # è½‰æ›ç‚ºçµ•å°åº§æ¨™ï¼Œç¢ºä¿æ•´æ•¸é‹ç®—
                                            x_left = (x_center - width/2) * img_width
                                            y_top = (y_center - height/2) * img_height
                                            box_w = width * img_width
                                            box_h = height * img_height
                                            
                                            # è½‰ç‚ºæ•´æ•¸ä¸¦ç¢ºä¿é‚Šç•Œ
                                            x = max(0, int(x_left))
                                            y = max(0, int(y_top))
                                            w = max(10, min(int(box_w), img_width - x))
                                            h = max(10, min(int(box_h), img_height - y))
                                            
                                            # å†æ¬¡æª¢æŸ¥é‚Šç•Œï¼Œç¢ºä¿ä¸æœƒè¶…å‡ºå½±åƒç¯„åœ
                                            if x + w > img_width:
                                                w = img_width - x
                                            if y + h > img_height:
                                                h = img_height - y
                                            
                                            # ç¢ºä¿æœ€å°å°ºå¯¸å’Œæœ‰æ•ˆæ€§
                                            if (w >= 10 and h >= 10 and 
                                                x >= 0 and y >= 0 and 
                                                x + w <= img_width and 
                                                y + h <= img_height):
                                                annotations.append((x, y, w, h))
                                                print(f"  æ¨™è¨» {line_num}: ({x}, {y}, {w}, {h})")
                                            else:
                                                invalid_annotations.append(f"{annotation_file.name}:è¡Œ{line_num} - é‚Šç•Œæ¡†ç„¡æ•ˆ: ({x}, {y}, {w}, {h}) vs å½±åƒå°ºå¯¸ ({img_width}, {img_height})")
                                                
                                        except ValueError as e:
                                            invalid_annotations.append(f"{annotation_file.name}:è¡Œ{line_num} - æ•¸å€¼æ ¼å¼éŒ¯èª¤: {e}")
                                    
                    except Exception as e:
                        print(f"è®€å–æ¨™è¨»æª”æ¡ˆæ™‚å‡ºéŒ¯ {annotation_file}: {e}")
                        continue

                    if annotations:
                        positive_data.append((img_path, annotations))

        if not positive_data:
            raise ValueError("æ‰¾ä¸åˆ°æœ‰æ•ˆçš„æ­£æ¨£æœ¬æ¨™è¨»è³‡æ–™")

        if invalid_annotations:
            print(f"âš ï¸  ç™¼ç¾ {len(invalid_annotations)} å€‹ç„¡æ•ˆæ¨™è¨»:")
            for error in invalid_annotations[:5]:  # åªé¡¯ç¤ºå‰5å€‹
                print(f"   {error}")
            if len(invalid_annotations) > 5:
                print(f"   ... é‚„æœ‰ {len(invalid_annotations)-5} å€‹éŒ¯èª¤")

        # å¯«å…¥æ­£æ¨£æœ¬æè¿°æª”æ¡ˆï¼Œä½¿ç”¨ç›¸å°è·¯å¾‘
        with open(positive_list_file, 'w') as f:
            for img_path, annotations in positive_data:
                # ä½¿ç”¨ç›¸å°æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„çš„è·¯å¾‘ï¼Œç¢ºä¿æ ¼å¼æ­£ç¢º
                rel_path = str(img_path.relative_to(self.project_dir)).replace('\\', '/')
                line = f"{rel_path} {len(annotations)}"
                for x, y, w, h in annotations:
                    line += f" {x} {y} {w} {h}"
                f.write(line + "\n")

        print(f"âœ“ æº–å‚™äº† {len(positive_data)} å€‹æ­£æ¨£æœ¬å½±åƒ")
        total_objects = sum(len(annotations) for _, annotations in positive_data)
        print(f"ç¸½å…± {total_objects} å€‹æ»‘æ¿è»Šæ¨™è¨»")
        print(f"æ­£æ¨£æœ¬åˆ—è¡¨: {positive_list_file}")
        
        # é¡¯ç¤ºå‰å¹¾è¡Œå…§å®¹ä»¥ä¾¿èª¿è©¦
        print("æ­£æ¨£æœ¬åˆ—è¡¨æª”æ¡ˆå…§å®¹é è¦½:")
        with open(positive_list_file, 'r') as f:
            for i, line in enumerate(f):
                if i >= 3:
                    break
                print(f"  {line.strip()}")

        return str(positive_list_file)

    def prepare_negative_samples(self):
        """
        æº–å‚™è² æ¨£æœ¬æè¿°æª”æ¡ˆ

        Returns:
            str: è² æ¨£æœ¬æè¿°æª”æ¡ˆè·¯å¾‘
        """
        negative_list_file = self.data_dir / "negative_images.txt"

        # ç²å–æ‰€æœ‰è² æ¨£æœ¬å½±åƒ
        negative_images = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.JPG', '*.JPEG', '*.PNG', '*.BMP']:
            negative_images.extend(self.negative_dir.glob(ext))

        if not negative_images:
            raise ValueError(f"åœ¨ {self.negative_dir} ä¸­æ‰¾ä¸åˆ°è² æ¨£æœ¬å½±åƒ")

        # å¯«å…¥æè¿°æª”æ¡ˆï¼Œä½¿ç”¨ç›¸å°è·¯å¾‘
        with open(negative_list_file, 'w') as f:
            for img_path in negative_images:
                # ä½¿ç”¨ç›¸å°æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„çš„è·¯å¾‘ï¼Œç¢ºä¿æ ¼å¼æ­£ç¢º
                rel_path = str(img_path.relative_to(self.project_dir)).replace('\\', '/')
                f.write(f"{rel_path}\n")

        print(f"âœ“ æº–å‚™äº† {len(negative_images)} å€‹è² æ¨£æœ¬")
        print(f"è² æ¨£æœ¬åˆ—è¡¨: {negative_list_file}")
        
        # é¡¯ç¤ºå‰å¹¾è¡Œå…§å®¹ä»¥ä¾¿èª¿è©¦
        print("è² æ¨£æœ¬åˆ—è¡¨æª”æ¡ˆå…§å®¹é è¦½:")
        with open(negative_list_file, 'r') as f:
            for i, line in enumerate(f):
                if i >= 3:
                    break
                print(f"  {line.strip()}")

        return str(negative_list_file)

    def create_samples_python(self, positive_list_file, negative_list_file, 
                             num_samples=None, sample_width=24, sample_height=24):
        """
        ä½¿ç”¨ç´”Pythonå‰µå»ºè¨“ç·´æ¨£æœ¬ï¼ˆæ›¿ä»£opencv_createsamplesï¼‰

        Args:
            positive_list_file (str): æ­£æ¨£æœ¬åˆ—è¡¨æª”æ¡ˆ
            negative_list_file (str): è² æ¨£æœ¬åˆ—è¡¨æª”æ¡ˆ
            num_samples (int): è¦ç”Ÿæˆçš„æ¨£æœ¬æ•¸é‡
            sample_width (int): æ¨£æœ¬å¯¬åº¦
            sample_height (int): æ¨£æœ¬é«˜åº¦

        Returns:
            str: ç”Ÿæˆçš„.vecæª”æ¡ˆè·¯å¾‘
        """
        vec_file = self.data_dir / "positive_samples.vec"
        
        print("ä½¿ç”¨Pythonæ›¿ä»£æ–¹æ¡ˆå‰µå»ºè¨“ç·´æ¨£æœ¬...")
        
        # è®€å–æ­£æ¨£æœ¬è³‡è¨Š
        positive_samples = []
        with open(positive_list_file, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 6:  # æª”å + æ•¸é‡ + è‡³å°‘ä¸€çµ„åº§æ¨™
                    img_path = self.project_dir / parts[0]
                    count = int(parts[1])
                    
                    for i in range(count):
                        if len(parts) >= 6 + i * 4:
                            x, y, w, h = map(int, parts[2 + i * 4:6 + i * 4])
                            positive_samples.append((str(img_path), x, y, w, h))

        if not positive_samples:
            raise ValueError("æ²’æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ­£æ¨£æœ¬")

        # é™åˆ¶æ¨£æœ¬æ•¸é‡
        if num_samples is None:
            num_samples = min(len(positive_samples), 100)
        
        num_samples = min(num_samples, len(positive_samples))
        
        print(f"æ‰¾åˆ° {len(positive_samples)} å€‹æ­£æ¨£æœ¬ï¼Œå°‡ä½¿ç”¨ {num_samples} å€‹")

        # å‰µå»ºvecæª”æ¡ˆ
        samples_created = 0
        vec_data = []
        
        for i, (img_path, x, y, w, h) in enumerate(positive_samples[:num_samples]):
            try:
                # è®€å–å½±åƒ
                img = cv2.imread(img_path)
                if img is None:
                    print(f"ç„¡æ³•è®€å–å½±åƒ: {img_path}")
                    continue
                
                # æå–ROI
                roi = img[y:y+h, x:x+w]
                if roi.size == 0:
                    print(f"ç„¡æ•ˆçš„ROI: ({x}, {y}, {w}, {h}) in {img_path}")
                    continue
                
                # èª¿æ•´å¤§å°
                roi_resized = cv2.resize(roi, (sample_width, sample_height))
                
                # è½‰ç‚ºç°éš
                if len(roi_resized.shape) == 3:
                    roi_gray = cv2.cvtColor(roi_resized, cv2.COLOR_BGR2GRAY)
                else:
                    roi_gray = roi_resized
                
                # æ·»åŠ åˆ°vecè³‡æ–™
                vec_data.append(roi_gray)
                samples_created += 1
                
                if samples_created % 10 == 0:
                    print(f"å·²è™•ç† {samples_created}/{num_samples} å€‹æ¨£æœ¬")
                    
            except Exception as e:
                print(f"è™•ç†æ¨£æœ¬æ™‚å‡ºéŒ¯ {img_path}: {e}")
                continue

        if samples_created == 0:
            raise ValueError("ç„¡æ³•å‰µå»ºä»»ä½•æœ‰æ•ˆæ¨£æœ¬")

        # å¯«å…¥æ¨™æº–OpenCV vecæª”æ¡ˆæ ¼å¼
        print(f"å¯«å…¥vecæª”æ¡ˆ: {vec_file}")
        
        # è¨ˆç®—æª”æ¡ˆå¤§å°
        image_size = sample_width * sample_height
        
        with open(vec_file, 'wb') as f:
            # å¯«å…¥æª”é ­ï¼ˆOpenCVæ¨™æº–æ ¼å¼ï¼‰
            f.write(samples_created.to_bytes(4, 'little'))     # æ¨£æœ¬æ•¸é‡
            f.write(image_size.to_bytes(4, 'little'))          # æ¯å€‹æ¨£æœ¬çš„å¤§å°ï¼ˆå¯¬*é«˜ï¼‰
            f.write(sample_width.to_bytes(4, 'little'))        # å¯¬åº¦
            f.write(sample_height.to_bytes(4, 'little'))       # é«˜åº¦
            
            # å¯«å…¥æ¯å€‹æ¨£æœ¬
            for i, sample in enumerate(vec_data):
                # æ¯å€‹æ¨£æœ¬å‰é‚„éœ€è¦å¯«å…¥æ¨£æœ¬ç´¢å¼•ï¼ˆ4å­—ç¯€ï¼‰
                f.write(i.to_bytes(4, 'little'))
                
                # ç¢ºä¿æ¨£æœ¬æ˜¯æ­£ç¢ºçš„å°ºå¯¸
                if sample.shape != (sample_height, sample_width):
                    sample = cv2.resize(sample, (sample_width, sample_height))
                
                # å¯«å…¥åƒç´ æ•¸æ“šï¼ˆæŒ‰è¡Œå„ªå…ˆé †åºï¼‰
                sample_bytes = sample.astype(np.uint8).tobytes()
                f.write(sample_bytes)

        # é©—è­‰å¯«å…¥çš„æª”æ¡ˆ
        file_size = vec_file.stat().st_size
        expected_size = 16 + samples_created * (4 + image_size)  # æª”é ­16å­—ç¯€ + æ¯æ¨£æœ¬(4å­—ç¯€ç´¢å¼• + åœ–åƒæ•¸æ“š)
        
        print(f"âœ“ æˆåŠŸå‰µå»º {samples_created} å€‹è¨“ç·´æ¨£æœ¬")
        print(f"Vecæª”æ¡ˆ: {vec_file}")
        print(f"æª”æ¡ˆå¤§å°: {file_size:,} bytes (é æœŸ: {expected_size:,} bytes)")
        
        if abs(file_size - expected_size) > 100:  # å…è¨±å°èª¤å·®
            print(f"âš ï¸  æª”æ¡ˆå¤§å°ä¸ç¬¦é æœŸï¼Œå¯èƒ½æœ‰æ ¼å¼å•é¡Œ")
        
        return str(vec_file)

    def create_samples_opencv_format(self, positive_list_file, negative_list_file, 
                                   num_samples=None, sample_width=24, sample_height=24):
        """
        å‰µå»ºç¬¦åˆOpenCVæ ¼å¼çš„vecæª”æ¡ˆçš„å‚™é¸æ–¹æ³•
        """
        print("å˜—è©¦ä½¿ç”¨opencv-pythonç›´æ¥å‰µå»ºvecæª”æ¡ˆ...")
        
        vec_file = self.data_dir / "positive_samples_alt.vec"
        
        # è®€å–æ‰€æœ‰æ­£æ¨£æœ¬
        samples = []
        with open(positive_list_file, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 6:
                    img_path = self.project_dir / parts[0]
                    count = int(parts[1])
                    
                    # è®€å–å½±åƒ
                    img = cv2.imread(str(img_path))
                    if img is None:
                        continue
                    
                    for i in range(count):
                        if len(parts) >= 6 + i * 4:
                            x, y, w, h = map(int, parts[2 + i * 4:6 + i * 4])
                            
                            # æå–ROIä¸¦èª¿æ•´å°ºå¯¸
                            roi = img[y:y+h, x:x+w]
                            if roi.size > 0:
                                resized = cv2.resize(roi, (sample_width, sample_height))
                                gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY) if len(resized.shape) == 3 else resized
                                samples.append(gray)

        if not samples:
            raise ValueError("ç„¡æ³•å‰µå»ºä»»ä½•æ¨£æœ¬")

        # é™åˆ¶æ•¸é‡
        if num_samples and num_samples < len(samples):
            samples = samples[:num_samples]

        print(f"æº–å‚™å¯«å…¥ {len(samples)} å€‹æ¨£æœ¬åˆ°vecæª”æ¡ˆ")

        # ä½¿ç”¨æ›´ç°¡åŒ–çš„æ ¼å¼
        with open(vec_file, 'wb') as f:
            # ç°¡åŒ–çš„æª”é ­
            f.write(len(samples).to_bytes(4, 'little'))
            f.write((sample_width * sample_height).to_bytes(4, 'little'))
            f.write(sample_width.to_bytes(4, 'little'))
            f.write(sample_height.to_bytes(4, 'little'))
            
            # ç›´æ¥å¯«å…¥åœ–åƒæ•¸æ“šï¼Œä¸ä½¿ç”¨é¡å¤–çš„ç´¢å¼•
            for sample in samples:
                f.write(sample.tobytes())

        print(f"âœ“ å‰µå»ºæ›¿ä»£vecæª”æ¡ˆ: {vec_file}")
        return str(vec_file)

    def create_samples(self, positive_list_file, negative_list_file, 
                      num_samples=None, sample_width=24, sample_height=24):
        """
        å‰µå»ºè¨“ç·´æ¨£æœ¬ï¼ˆå˜—è©¦å¤šç¨®æ–¹æ³•ï¼‰

        Args:
            positive_list_file (str): æ­£æ¨£æœ¬åˆ—è¡¨æª”æ¡ˆ
            negative_list_file (str): è² æ¨£æœ¬åˆ—è¡¨æª”æ¡ˆ
            num_samples (int): è¦ç”Ÿæˆçš„æ¨£æœ¬æ•¸é‡ï¼ˆå¦‚æœç‚ºNoneå‰‡è‡ªå‹•è¨ˆç®—ï¼‰
            sample_width (int): æ¨£æœ¬å¯¬åº¦
            sample_height (int): æ¨£æœ¬é«˜åº¦

        Returns:
            str: ç”Ÿæˆçš„.vecæª”æ¡ˆè·¯å¾‘
        """
        # è¨ˆç®—å¯¦éš›å¯ç”¨çš„æ¨™è¨»æ•¸é‡
        total_annotations = 0
        with open(positive_list_file, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 2:
                    try:
                        annotation_count = int(parts[1])
                        total_annotations += annotation_count
                    except ValueError:
                        continue

        # å¦‚æœæ²’æœ‰æŒ‡å®šæ¨£æœ¬æ•¸é‡ï¼Œå‰‡æ ¹æ“šå¯ç”¨çš„æ¨™è¨»æ•¸é‡è¨ˆç®—
        if num_samples is None:
            # ä½¿ç”¨å¯ç”¨æ¨™è¨»çš„80%ï¼Œä½†ä¸è¶…é100ï¼ˆé©åˆå°è³‡æ–™é›†ï¼‰
            num_samples = min(int(total_annotations * 0.8), 100)
            print(f"è‡ªå‹•è¨­å®šæ¨£æœ¬æ•¸é‡ç‚º: {num_samples}ï¼ˆåŸºæ–¼ {total_annotations} å€‹æ¨™è¨»ï¼‰")

        # é¦–å…ˆå˜—è©¦ä½¿ç”¨opencv_createsamplesï¼ˆä½†æˆ‘å€‘çŸ¥é“æœƒå¤±æ•—ï¼‰
        print("å˜—è©¦ä½¿ç”¨ opencv_createsamplesï¼ˆé æœŸæœƒå¤±æ•—ï¼‰...")
        
        # ç›´æ¥ä½¿ç”¨Pythonæ–¹æ³•ï¼Œå› ç‚ºæˆ‘å€‘çŸ¥é“opencv_createsamplesæœ‰å•é¡Œ
        try:
            # å…ˆå˜—è©¦æ¨™æº–æ ¼å¼
            return self.create_samples_python(
                positive_list_file, negative_list_file,
                num_samples, sample_width, sample_height
            )
        except Exception as e:
            print(f"æ¨™æº–æ ¼å¼å¤±æ•—: {e}")
            print("å˜—è©¦æ›¿ä»£æ ¼å¼...")
            
            # å¦‚æœæ¨™æº–æ ¼å¼å¤±æ•—ï¼Œå˜—è©¦ç°¡åŒ–æ ¼å¼
            return self.create_samples_opencv_format(
                positive_list_file, negative_list_file,
                num_samples, sample_width, sample_height
            )

    def train_cascade_python_check(self):
        """
        æª¢æŸ¥æ˜¯å¦å¯ä»¥ä½¿ç”¨opencv_traincascade
        """
        try:
            result = subprocess.run(["opencv_traincascade"], 
                                  capture_output=True, text=True, timeout=10)
            return True
        except (FileNotFoundError, subprocess.TimeoutExpired):
            return False

    def safe_rmtree(self, path):
        """
        å®‰å…¨åœ°åˆªé™¤ç›®éŒ„ï¼Œè™•ç†æ¬Šé™å•é¡Œ
        
        Args:
            path: è¦åˆªé™¤çš„ç›®éŒ„è·¯å¾‘
        """
        if not path.exists():
            return
        
        max_attempts = 3
        for attempt in range(max_attempts):
            try:
                print(f"å˜—è©¦æ¸…ç†ç›®éŒ„ {path} (ç¬¬{attempt+1}æ¬¡)")
                
                # æ–¹æ³•1: å˜—è©¦ä¿®æ”¹æ‰€æœ‰æª”æ¡ˆæ¬Šé™
                for root, dirs, files in os.walk(path):
                    for d in dirs:
                        dir_path = os.path.join(root, d)
                        try:
                            os.chmod(dir_path, stat.S_IWRITE | stat.S_IREAD | stat.S_IEXEC)
                        except:
                            pass
                    for f in files:
                        file_path = os.path.join(root, f)
                        try:
                            os.chmod(file_path, stat.S_IWRITE | stat.S_IREAD)
                        except:
                            pass
                
                # å˜—è©¦åˆªé™¤
                def handle_remove_readonly(func, path, exc):
                    """è™•ç†åªè®€æª”æ¡ˆçš„åˆªé™¤"""
                    try:
                        if os.path.exists(path):
                            os.chmod(path, stat.S_IWRITE)
                            func(path)
                    except:
                        pass
                
                shutil.rmtree(path, onerror=handle_remove_readonly)
                print(f"âœ“ æˆåŠŸæ¸…ç†ç›®éŒ„")
                return
                
            except Exception as e:
                print(f"æ¸…ç†å˜—è©¦ {attempt+1} å¤±æ•—: {e}")
                if attempt < max_attempts - 1:
                    time.sleep(1)  # ç­‰å¾…ä¸€ç§’å¾Œé‡è©¦
                continue
        
        # å¦‚æœæ‰€æœ‰å˜—è©¦éƒ½å¤±æ•—ï¼Œå‰µå»ºæ–°ç›®éŒ„
        print(f"âš ï¸  ç„¡æ³•æ¸…ç†ç›®éŒ„ {path}ï¼Œå‰µå»ºæ–°çš„è¼¸å‡ºç›®éŒ„...")
        import uuid
        timestamp = int(time.time())
        new_name = f"trained_model_{timestamp}"
        self.output_dir = self.data_dir / new_name
        self.output_dir.mkdir(parents=True, exist_ok=True)
        print(f"ä½¿ç”¨æ–°ç›®éŒ„: {self.output_dir}")

    def train_cascade(self, vec_file, negative_list_file, 
                     num_pos=None, num_neg=None, num_stages=20,
                     sample_width=24, sample_height=24):
        """
        è¨“ç·´Haar cascadeåˆ†é¡å™¨

        Args:
            vec_file (str): æ­£æ¨£æœ¬.vecæª”æ¡ˆ
            negative_list_file (str): è² æ¨£æœ¬åˆ—è¡¨æª”æ¡ˆ
            num_pos (int): æ­£æ¨£æœ¬æ•¸é‡ï¼ˆå¦‚æœç‚ºNoneå‰‡è‡ªå‹•è¨ˆç®—ï¼‰
            num_neg (int): è² æ¨£æœ¬æ•¸é‡ï¼ˆå¦‚æœç‚ºNoneå‰‡è‡ªå‹•è¨ˆç®—ï¼‰
            num_stages (int): è¨“ç·´éšæ®µæ•¸
            sample_width (int): æ¨£æœ¬å¯¬åº¦
            sample_height (int): æ¨£æœ¬é«˜åº¦
        """
        # æª¢æŸ¥opencv_traincascadeæ˜¯å¦å¯ç”¨
        if not self.train_cascade_python_check():
            print("âœ— æ‰¾ä¸åˆ° opencv_traincascade å·¥å…·")
            print("è«‹å®‰è£å®Œæ•´çš„OpenCVå¥—ä»¶:")
            print("  conda install opencv")
            print("  æˆ–ä¸‹è¼‰OpenCVå®˜æ–¹ç‰ˆæœ¬")
            
            # å˜—è©¦æä¾›æ›¿ä»£å»ºè­°
            print("\næ›¿ä»£æ–¹æ¡ˆ:")
            print("1. ä½¿ç”¨ç·šä¸ŠColabç’°å¢ƒ:")
            print("   https://colab.research.google.com/")
            print("2. ä½¿ç”¨Dockerå®¹å™¨:")
            print("   docker run -it opencv/opencv:latest")
            print("3. å®‰è£å®Œæ•´çš„OpenCV-contrib-python:")
            print("   pip uninstall opencv-python")
            print("   pip install opencv-contrib-python")
            
            return None

        # è‡ªå‹•è¨ˆç®—åˆé©çš„æ­£è² æ¨£æœ¬æ•¸é‡ï¼ˆæ›´ä¿å®ˆçš„è¨­å®šä»¥æ¸›å°‘èª¤åµæ¸¬ï¼‰
        if num_pos is None:
            # å¾æ­£æ¨£æœ¬åˆ—è¡¨æª”æ¡ˆè¨ˆç®—å¯¦éš›æ¨£æœ¬æ•¸
            try:
                with open(self.data_dir / "positive_images.txt", 'r') as f:
                    lines = f.readlines()
                total_annotations = 0
                for line in lines:
                    parts = line.strip().split()
                    if len(parts) >= 2:
                        total_annotations += int(parts[1])
                
                # ä½¿ç”¨20%çš„æ¨™è¨»ä½œç‚ºè¨“ç·´æ¨£æœ¬ï¼ˆæ›´ä¿å®ˆï¼Œæ¸›å°‘éæ“¬åˆï¼‰
                num_pos = min(int(total_annotations * 0.2), 20)
            except:
                num_pos = 15  # éå¸¸ä¿å®ˆçš„é è¨­å€¼
            print(f"è‡ªå‹•è¨­å®šæ­£æ¨£æœ¬æ•¸é‡ç‚º: {num_pos}")

        if num_neg is None:
            with open(negative_list_file, 'r') as f:
                total_neg = len(f.readlines())
            # å¢åŠ è² æ¨£æœ¬æ¯”ä¾‹ä»¥æ¸›å°‘èª¤åµæ¸¬
            num_neg = min(int(total_neg * 0.4), num_pos * 5)  # è² æ¨£æœ¬ç‚ºæ­£æ¨£æœ¬çš„5å€
            print(f"è‡ªå‹•è¨­å®šè² æ¨£æœ¬æ•¸é‡ç‚º: {num_neg}")

        # å®‰å…¨åœ°æ¸…ç†è¼¸å‡ºç›®éŒ„
        print(f"æº–å‚™è¼¸å‡ºç›®éŒ„: {self.output_dir}")
        self.safe_rmtree(self.output_dir)
        
        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # é©—è­‰ç›®éŒ„æ˜¯å¦å¯å¯«
        test_file = self.output_dir / "test_write.txt"
        try:
            with open(test_file, 'w') as f:
                f.write("test")
            test_file.unlink()
            print(f"âœ“ è¼¸å‡ºç›®éŒ„å¯å¯«å…¥")
        except Exception as e:
            print(f"âœ— è¼¸å‡ºç›®éŒ„ç„¡æ³•å¯«å…¥: {e}")
            # æœ€å¾Œå˜—è©¦ï¼šä½¿ç”¨è‡¨æ™‚ç›®éŒ„
            import tempfile
            temp_dir = Path(tempfile.mkdtemp(prefix="haar_training_"))
            print(f"ä½¿ç”¨è‡¨æ™‚ç›®éŒ„: {temp_dir}")
            self.output_dir = temp_dir

        # æ§‹å»ºopencv_traincascadeå‘½ä»¤ - èª¿æ•´åƒæ•¸ä»¥æ¸›å°‘èª¤åµæ¸¬
        cmd = [
            "opencv_traincascade",
            "-data", str(self.output_dir),
            "-vec", vec_file,
            "-bg", negative_list_file,
            "-numPos", str(num_pos),
            "-numNeg", str(num_neg),
            "-numStages", str(num_stages),
            "-w", str(sample_width),
            "-h", str(sample_height),
            "-minHitRate", "0.999",        # æé«˜å‘½ä¸­ç‡è¦æ±‚ï¼ˆæ¸›å°‘æ¼åµæ¸¬ï¼‰
            "-maxFalseAlarmRate", "0.3",   # é™ä½èª¤å ±ç‡å®¹å¿åº¦ï¼ˆæ¸›å°‘èª¤åµæ¸¬ï¼‰
            "-weightTrimRate", "0.95",
            "-maxDepth", "2",              # å¢åŠ æ±ºç­–æ¨¹æ·±åº¦ï¼ˆæé«˜ç²¾ç¢ºåº¦ï¼‰
            "-maxWeakCount", "150",        # å¢åŠ å¼±åˆ†é¡å™¨æ•¸é‡ï¼ˆæé«˜ç²¾ç¢ºåº¦ï¼‰
            "-mode", "ALL",                # ä½¿ç”¨æ‰€æœ‰ç‰¹å¾µé¡å‹
            "-precalcValBufSize", "2048",  # å¢åŠ ç·©è¡å€å¤§å°
            "-precalcIdxBufSize", "2048"
        ]

        print(f"é–‹å§‹è¨“ç·´é«˜ç²¾ç¢ºåº¦Haar cascadeåˆ†é¡å™¨...")
        print(f"âš ï¸  ä½¿ç”¨æ›´åš´æ ¼çš„åƒæ•¸ä»¥æ¸›å°‘èª¤åµæ¸¬")
        print(f"é è¨ˆéœ€è¦æ™‚é–“: 30åˆ†é˜åˆ°4å°æ™‚ï¼ˆå–æ±ºæ–¼è³‡æ–™é‡ï¼‰")
        print(f"è¨“ç·´åƒæ•¸:")
        print(f"  æ­£æ¨£æœ¬: {num_pos}")
        print(f"  è² æ¨£æœ¬: {num_neg}")
        print(f"  éšæ®µæ•¸: {num_stages}")
        print(f"  æ¨£æœ¬å°ºå¯¸: {sample_width}x{sample_height}")
        print(f"  å‘½ä¸­ç‡è¦æ±‚: 99.9%")
        print(f"  èª¤å ±ç‡å®¹å¿: 30%")
        print(f"  è¼¸å‡ºç›®éŒ„: {self.output_dir}")
        print(f"\nâ±ï¸  è¨“ç·´é–‹å§‹æ™‚é–“: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        print("æŒ‰ Ctrl+C å¯ä¸­æ–·è¨“ç·´")

        try:
            # ä½¿ç”¨Popenä»¥ä¾¿å³æ™‚é¡¯ç¤ºè¼¸å‡º
            start_time = time.time()
            process = subprocess.Popen(cmd, stdout=subprocess.PIPE, 
                                     stderr=subprocess.STDOUT, text=True,
                                     cwd=str(self.project_dir))

            # å³æ™‚é¡¯ç¤ºè¨“ç·´é€²åº¦
            stage_count = 0
            for line in process.stdout:
                line_clean = line.rstrip()
                print(line_clean)
                
                # è¿½è¹¤è¨“ç·´é€²åº¦
                if "STAGE" in line_clean:
                    stage_count += 1
                    progress = (stage_count / num_stages) * 100
                    elapsed = time.time() - start_time
                    estimated_total = elapsed / stage_count * num_stages
                    remaining = estimated_total - elapsed
                    
                    print(f">>> è¨“ç·´é€²åº¦: ç¬¬ {stage_count}/{num_stages} éšæ®µ ({progress:.1f}%)")
                    print(f"    å·²ç”¨æ™‚é–“: {elapsed/60:.1f} åˆ†é˜")
                    if remaining > 0:
                        print(f"    é è¨ˆå‰©é¤˜: {remaining/60:.1f} åˆ†é˜")

            process.wait()

            if process.returncode == 0:
                cascade_file = self.output_dir / "cascade.xml"
                if cascade_file.exists():
                    total_time = time.time() - start_time
                    print(f"\nğŸ‰ é«˜ç²¾ç¢ºåº¦æ¨¡å‹è¨“ç·´å®Œæˆ!")
                    print(f"â±ï¸  ç¸½è¨“ç·´æ™‚é–“: {total_time/60:.1f} åˆ†é˜")
                    print(f"ğŸ“ æ¨¡å‹æª”æ¡ˆ: {cascade_file}")
                    
                    # é¡¯ç¤ºæ¨¡å‹è³‡è¨Š
                    file_size = cascade_file.stat().st_size
                    print(f"ğŸ“Š æ¨¡å‹æª”æ¡ˆå¤§å°: {file_size:,} bytes")
                    
                    # å¦‚æœä½¿ç”¨è‡¨æ™‚ç›®éŒ„ï¼Œè¤‡è£½åˆ°åŸç›®æ¨™ä½ç½®
                    if "temp" in str(self.output_dir):
                        try:
                            final_dir = self.data_dir / "trained_model"
                            final_dir.mkdir(exist_ok=True)
                            final_cascade = final_dir / "cascade.xml"
                            shutil.copy2(cascade_file, final_cascade)
                            print(f"ğŸ“‹ æ¨¡å‹å·²è¤‡è£½åˆ°: {final_cascade}")
                            cascade_file = final_cascade
                        except Exception as e:
                            print(f"âš ï¸  ç„¡æ³•è¤‡è£½æ¨¡å‹æª”æ¡ˆ: {e}")
                    
                    # æä¾›ä½¿ç”¨å»ºè­°
                    print("\nğŸ“‹ é«˜ç²¾ç¢ºåº¦æ¨¡å‹ä½¿ç”¨èªªæ˜:")
                    print(f"1. æ¸¬è©¦æ¨¡å‹: python demo.py --cascade {cascade_file}")
                    print("2. å»ºè­°çš„åµæ¸¬åƒæ•¸ï¼ˆæ¸›å°‘èª¤åµæ¸¬ï¼‰:")
                    print("   - scaleFactor: 1.1-1.2ï¼ˆè¼ƒå¤§å€¼ï¼Œæ¸›å°‘è¨ˆç®—ï¼‰")
                    print("   - minNeighbors: 5-10ï¼ˆè¼ƒå¤§å€¼ï¼Œæ¸›å°‘èª¤åµæ¸¬ï¼‰")
                    print("   - minSize: (40,40) æˆ–æ›´å¤§ï¼ˆéæ¿¾å°ç‰©ä»¶ï¼‰")
                    print("   - maxSize: è¨­å®šåˆç†çš„æœ€å¤§å°ºå¯¸")
                    print("\n3. å¦‚æœä»æœ‰èª¤åµæ¸¬:")
                    print("   - æ”¶é›†æ›´å¤šè² æ¨£æœ¬ï¼ˆåŒ…å«å¸¸è¦‹çš„èª¤åµæ¸¬ç‰©ä»¶ï¼‰")
                    print("   - å¢åŠ è¨“ç·´éšæ®µæ•¸åˆ°15-20")
                    print("   - æª¢æŸ¥ä¸¦æ”¹å–„æ­£æ¨£æœ¬æ¨™è¨»å“è³ª")
                    
                    return str(cascade_file)
                else:
                    raise RuntimeError("è¨“ç·´å®Œæˆä½†æ‰¾ä¸åˆ°cascade.xmlæª”æ¡ˆ")
            else:
                raise RuntimeError(f"è¨“ç·´å¤±æ•—ï¼Œé€€å‡ºç¢¼: {process.returncode}")

        except KeyboardInterrupt:
            print(f"\nâ¹ï¸  è¨“ç·´è¢«ç”¨æˆ¶ä¸­æ–·")
            if process:
                process.terminate()
                print("æ­£åœ¨æ¸…ç†...")
                time.sleep(2)
            raise
        except FileNotFoundError:
            print("âœ— æ‰¾ä¸åˆ° opencv_traincascade å·¥å…·")
            print("è«‹ç¢ºä¿å·²å®‰è£å®Œæ•´çš„OpenCVå¥—ä»¶")
            raise

    def validate_data(self):
        """
        é©—è­‰è¨“ç·´è³‡æ–™çš„å®Œæ•´æ€§
        """
        print("é©—è­‰è¨“ç·´è³‡æ–™...")

        # æª¢æŸ¥æ­£æ¨£æœ¬ï¼ˆé¿å…é‡è¤‡è¨ˆç®—åŒåæª”æ¡ˆï¼Œä¸åˆ†å¤§å°å¯«ï¼‰
        positive_images = []
        seen_pos = set()
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.JPG', '*.JPEG', '*.PNG', '*.BMP']:
            for img in self.positive_dir.glob(ext):
                name_lower = img.name.lower()
                if name_lower not in seen_pos:
                    positive_images.append(img)
                    seen_pos.add(name_lower)
        print(f"æ­£æ¨£æœ¬å½±åƒ: {len(positive_images)}")

        # æª¢æŸ¥è² æ¨£æœ¬ï¼ˆé¿å…é‡è¤‡è¨ˆç®—åŒåæª”æ¡ˆï¼Œä¸åˆ†å¤§å°å¯«ï¼‰
        negative_images = []
        seen_neg = set()
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.JPG', '*.JPEG', '*.PNG', '*.BMP']:
            for img in self.negative_dir.glob(ext):
                name_lower = img.name.lower()
                if name_lower not in seen_neg:
                    negative_images.append(img)
                    seen_neg.add(name_lower)
        print(f"è² æ¨£æœ¬å½±åƒ: {len(negative_images)}")

        # æª¢æŸ¥æ¨™è¨»æª”æ¡ˆ
        annotation_files = list(self.annotations_dir.glob("*.txt"))
        print(f"æ¨™è¨»æª”æ¡ˆ: {len(annotation_files)}")

        # æä¾›å»ºè­°
        issues = []
        if len(positive_images) < 50:
            issues.append(f"æ­£æ¨£æœ¬å½±åƒå¤ªå°‘ï¼ˆç•¶å‰: {len(positive_images)}ï¼Œå»ºè­°è‡³å°‘50å¼µï¼‰")

        if len(negative_images) < 100:
            issues.append(f"è² æ¨£æœ¬å½±åƒå¤ªå°‘ï¼ˆç•¶å‰: {len(negative_images)}ï¼Œå»ºè­°è‡³å°‘100å¼µï¼‰")

        if len(annotation_files) < len(positive_images) * 0.8:
            issues.append(f"æ¨™è¨»æª”æ¡ˆéå°‘ï¼ˆç•¶å‰: {len(annotation_files)}ï¼Œæ‡‰æ¥è¿‘æ­£æ¨£æœ¬æ•¸é‡ï¼‰")

        if issues:
            print("âš ï¸  ç™¼ç¾ä»¥ä¸‹å•é¡Œ:")
            for issue in issues:
                print(f"   {issue}")
            return False

        print("âœ“ è³‡æ–™é©—è­‰é€šé")
        return True

def main():
    parser = argparse.ArgumentParser(description='Haar Cascade Training for Scooter Detection')
    parser.add_argument('--project_dir', default='./', help='å°ˆæ¡ˆç›®éŒ„è·¯å¾‘')
    parser.add_argument('--num_samples', type=int, help='ç”Ÿæˆæ¨£æœ¬æ•¸é‡ï¼ˆè‡ªå‹•è¨ˆç®—å¦‚æœæœªæŒ‡å®šï¼‰')
    parser.add_argument('--num_pos', type=int, help='è¨“ç·´æ­£æ¨£æœ¬æ•¸é‡ï¼ˆè‡ªå‹•è¨ˆç®—å¦‚æœæœªæŒ‡å®šï¼‰')
    parser.add_argument('--num_neg', type=int, help='è¨“ç·´è² æ¨£æœ¬æ•¸é‡ï¼ˆè‡ªå‹•è¨ˆç®—å¦‚æœæœªæŒ‡å®šï¼‰')
    parser.add_argument('--num_stages', type=int, default=12, help='è¨“ç·´éšæ®µæ•¸ï¼ˆé è¨­12ï¼Œå¹³è¡¡ç²¾åº¦å’Œé€Ÿåº¦ï¼‰')
    parser.add_argument('--width', type=int, default=24, help='æ¨£æœ¬å¯¬åº¦')
    parser.add_argument('--height', type=int, default=24, help='æ¨£æœ¬é«˜åº¦')
    parser.add_argument('--validate_only', action='store_true', help='åƒ…é©—è­‰è³‡æ–™')
    parser.add_argument('--python_only', action='store_true', help='å¼·åˆ¶ä½¿ç”¨Pythonæ›¿ä»£æ–¹æ¡ˆ')
    parser.add_argument('--force_clean', action='store_true', help='å¼·åˆ¶æ¸…ç†è¼¸å‡ºç›®éŒ„')
    parser.add_argument('--high_precision', action='store_true', help='é«˜ç²¾ç¢ºåº¦æ¨¡å¼ï¼ˆæ¸›å°‘èª¤åµæ¸¬ï¼‰')

    args = parser.parse_args()

    try:
        # å‰µå»ºè¨“ç·´å™¨
        trainer = HaarCascadeTrainer(args.project_dir)

        # é«˜ç²¾ç¢ºåº¦æ¨¡å¼èª¿æ•´
        if args.high_precision:
            print("ğŸ¯ å•Ÿç”¨é«˜ç²¾ç¢ºåº¦æ¨¡å¼")
            args.num_stages = max(args.num_stages, 15)  # è‡³å°‘15å€‹éšæ®µ
            print(f"èª¿æ•´è¨“ç·´éšæ®µæ•¸ç‚º: {args.num_stages}")

        # å¼·åˆ¶æ¸…ç†ï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if args.force_clean:
            print("å¼·åˆ¶æ¸…ç†è¼¸å‡ºç›®éŒ„...")
            trainer.safe_rmtree(trainer.output_dir)

        # é©—è­‰è³‡æ–™
        if not trainer.validate_data():
            if not args.validate_only:
                print("âœ— è³‡æ–™é©—è­‰å¤±æ•—ï¼Œä½†ä»å˜—è©¦è¨“ç·´...")
                print("\nğŸ’¡ æ¸›å°‘èª¤åµæ¸¬çš„æ”¹å–„å»ºè­°:")
                print("1. æ”¶é›†æ›´å¤šå¤šæ¨£åŒ–çš„è² æ¨£æœ¬ï¼ˆåŒ…å«å®¹æ˜“èª¤åµæ¸¬çš„ç‰©ä»¶ï¼‰")
                print("2. ç¢ºä¿æ­£æ¨£æœ¬æ¨™è¨»ç²¾ç¢ºï¼ˆç·Šè²¼æ»‘æ¿è»Šé‚Šç•Œï¼‰")
                print("3. å¢åŠ ä¸åŒè§’åº¦ã€å…‰ç…§ã€è·é›¢çš„æ­£æ¨£æœ¬")
                print("4. ä½¿ç”¨ --high_precision æ¨¡å¼è¨“ç·´")
                print("5. è€ƒæ…®å¢åŠ è¨“ç·´éšæ®µæ•¸åˆ°15-20")
            else:
                return 1

        if args.validate_only:
            print("âœ“ è³‡æ–™é©—è­‰å®Œæˆ")
            return 0

        # æº–å‚™æ¨£æœ¬
        print("\n=== æº–å‚™è² æ¨£æœ¬ ===")
        negative_list = trainer.prepare_negative_samples()

        print("\n=== æº–å‚™æ­£æ¨£æœ¬ ===")
        positive_list = trainer.prepare_positive_samples()

        print("\n=== å‰µå»ºè¨“ç·´æ¨£æœ¬ ===")
        if args.python_only:
            vec_file = trainer.create_samples_python(
                positive_list, negative_list,
                num_samples=args.num_samples,
                sample_width=args.width,
                sample_height=args.height
            )
        else:
            vec_file = trainer.create_samples(
                positive_list, negative_list,
                num_samples=args.num_samples,
                sample_width=args.width,
                sample_height=args.height
            )

        print("\n=== é–‹å§‹è¨“ç·´ ===")
        if args.high_precision:
            print("ğŸ¯ ä½¿ç”¨é«˜ç²¾ç¢ºåº¦æ¨¡å¼è¨“ç·´...")
            
        cascade_file = trainer.train_cascade(
            vec_file, negative_list,
            num_pos=args.num_pos,
            num_neg=args.num_neg,
            num_stages=args.num_stages,
            sample_width=args.width,
            sample_height=args.height
        )

        if cascade_file:
            print(f"\nğŸ‰ è¨“ç·´å®Œæˆ! æ¨¡å‹æª”æ¡ˆ: {cascade_file}")
            print("\nğŸ“ æ¸¬è©¦å’Œèª¿å„ªæŒ‡å—:")
            print("1. åŸºæœ¬æ¸¬è©¦:")
            print(f"   python demo.py --cascade {cascade_file} --webcam")
            print("\n2. å¦‚æœæœ‰èª¤åµæ¸¬ï¼Œèª¿æ•´åµæ¸¬åƒæ•¸:")
            print("   - å¢åŠ  minNeighbors (5-10)")
            print("   - å¢åŠ  scaleFactor (1.1-1.2)")
            print("   - è¨­å®š minSize éæ¿¾å°ç‰©ä»¶")
            print("   - è¨­å®š maxSize é™åˆ¶å¤§ç‰©ä»¶")
            print("\n3. å¦‚æœæ•ˆæœä»ä¸ä½³:")
            print("   - æ”¶é›†æ›´å¤šåŒ…å«èª¤åµæ¸¬ç‰©ä»¶çš„è² æ¨£æœ¬")
            print("   - ä½¿ç”¨ --high_precision --num_stages 20 é‡æ–°è¨“ç·´")
            print("   - æª¢æŸ¥ä¸¦æ”¹å–„æ¨™è¨»å“è³ª")
        else:
            print("\nâŒ è¨“ç·´å¤±æ•—ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤è¨Šæ¯ä¸¦é‡è©¦")

    except KeyboardInterrupt:
        print("\nğŸ›‘ ç¨‹åºè¢«ç”¨æˆ¶ä¸­æ–·")
        return 0
    except Exception as e:
        print(f"âœ— è¨“ç·´å¤±æ•—: {e}")
        import traceback
        print("\nè©³ç´°éŒ¯èª¤è³‡è¨Š:")
        traceback.print_exc()
        
        print("\nğŸ”§ å¸¸è¦‹å•é¡Œè§£æ±ºæ–¹æ¡ˆ:")
        print("1. æ¬Šé™å•é¡Œ: ä»¥ç®¡ç†å“¡èº«ä»½åŸ·è¡Œæˆ–æ›´æ”¹å°ˆæ¡ˆç›®éŒ„")
        print("2. OpenCVå·¥å…·ç¼ºå¤±: å®‰è£ opencv-contrib-python")
        print("3. è¨˜æ†¶é«”ä¸è¶³: æ¸›å°‘æ¨£æœ¬æ•¸é‡æˆ–éšæ®µæ•¸")
        print("4. è³‡æ–™å•é¡Œ: æª¢æŸ¥æ¨™è¨»æª”æ¡ˆæ ¼å¼å’Œå½±åƒå®Œæ•´æ€§")
        
        return 1

    return 0

if __name__ == "__main__":
    exit(main())
