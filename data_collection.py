#!/usr/bin/env python3
"""
Data Collection Tool for Campus Scooter Detection
æ ¡åœ’æ»‘æ¿è»Šè³‡æ–™æ”¶é›†å·¥å…·

ç”¨æ–¼æ”¶é›†å’Œæ•´ç†è¨“ç·´è³‡æ–™çš„å·¥å…·
"""

import os
import cv2
import numpy as np
import argparse
from pathlib import Path
import shutil
import json
from datetime import datetime
import sys

# å¯é¸çš„ tkinter å°å…¥ï¼Œé¿å…åœ¨ç„¡åœ–å½¢ç•Œé¢ç’°å¢ƒä¸­å‡ºéŒ¯
try:
    import tkinter as tk
    from tkinter import filedialog, messagebox
    HAS_TKINTER = True
except ImportError:
    HAS_TKINTER = False
    print("è­¦å‘Š: ç„¡æ³•å°å…¥ tkinterï¼ŒGUI åŠŸèƒ½å°‡ä¸å¯ç”¨")

class DataCollector:
    def __init__(self, project_dir="./"):
        """
        åˆå§‹åŒ–è³‡æ–™æ”¶é›†å™¨

        Args:
            project_dir (str): å°ˆæ¡ˆç›®éŒ„è·¯å¾‘
        """
        try:
            self.project_dir = Path(project_dir)
            self.data_dir = self.project_dir / "data"
            self.positive_dir = self.data_dir / "positive"
            self.negative_dir = self.data_dir / "negative"
            self.annotations_dir = self.data_dir / "annotations"
            self.trained_model_dir = self.data_dir / "trained_model"

            # å‰µå»ºç›®éŒ„
            for dir_path in [self.positive_dir, self.negative_dir, self.annotations_dir, self.trained_model_dir]:
                dir_path.mkdir(parents=True, exist_ok=True)

            # çµ±è¨ˆè³‡è¨Š
            self.stats = {
                "positive_images": 0,
                "negative_images": 0,
                "annotations": 0,
                "last_updated": None
            }

            self.update_stats()
            print(f"âœ“ è³‡æ–™æ”¶é›†å™¨åˆå§‹åŒ–å®Œæˆ")
            print(f"å°ˆæ¡ˆç›®éŒ„: {self.project_dir.absolute()}")
            
        except Exception as e:
            print(f"åˆå§‹åŒ–å¤±æ•—: {e}")
            raise

    def update_stats(self):
        """æ›´æ–°è³‡æ–™çµ±è¨ˆ"""
        try:
            # çµ±è¨ˆæ­£æ¨£æœ¬ï¼ˆé¿å…é‡è¤‡è¨ˆç®—åŒåæª”æ¡ˆï¼Œä¸åˆ†å¤§å°å¯«ï¼‰
            positive_patterns = ["*.jpg", "*.png", "*.jpeg", "*.JPG", "*.PNG", "*.JPEG"]
            positive_images = []
            seen_pos = set()
            for pattern in positive_patterns:
                for img in self.positive_dir.glob(pattern):
                    name_lower = img.name.lower()
                    if name_lower not in seen_pos:
                        positive_images.append(img)
                        seen_pos.add(name_lower)
            self.stats["positive_images"] = len(positive_images)

            # çµ±è¨ˆè² æ¨£æœ¬ï¼ˆé¿å…é‡è¤‡è¨ˆç®—åŒåæª”æ¡ˆï¼Œä¸åˆ†å¤§å°å¯«ï¼‰
            negative_images = []
            seen_neg = set()
            for pattern in positive_patterns:
                for img in self.negative_dir.glob(pattern):
                    name_lower = img.name.lower()
                    if name_lower not in seen_neg:
                        negative_images.append(img)
                        seen_neg.add(name_lower)
            self.stats["negative_images"] = len(negative_images)

            # çµ±è¨ˆæ¨™è¨»æª”æ¡ˆ
            annotations = list(self.annotations_dir.glob("*.txt"))
            self.stats["annotations"] = len(annotations)

            self.stats["last_updated"] = datetime.now().isoformat()
            
        except Exception as e:
            print(f"æ›´æ–°çµ±è¨ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    def show_stats(self):
        """é¡¯ç¤ºè³‡æ–™çµ±è¨ˆ"""
        self.update_stats()
        print("\n=== æ ¡åœ’æ»‘æ¿è»Šåµæ¸¬ - è³‡æ–™çµ±è¨ˆ ===")
        print(f"æ­£æ¨£æœ¬å½±åƒ: {self.stats['positive_images']}")
        print(f"è² æ¨£æœ¬å½±åƒ: {self.stats['negative_images']}")
        print(f"æ¨™è¨»æª”æ¡ˆ: {self.stats['annotations']}")
        print(f"æœ€å¾Œæ›´æ–°: {self.stats['last_updated']}")

        # æª¢æŸ¥è³‡æ–™å®Œæ•´æ€§
        missing_annotations = self.stats['positive_images'] - self.stats['annotations']
        if missing_annotations > 0:
            print(f"âš ï¸  ç¼ºå°‘ {missing_annotations} å€‹æ¨™è¨»æª”æ¡ˆ")
        
        # å»ºè­°è¨“ç·´åƒæ•¸
        if self.stats['positive_images'] >= 200:
            suggested_pos = min(int(self.stats['positive_images'] * 0.9), 1800)
            suggested_neg = min(int(self.stats['negative_images'] * 0.9), 3600)
            print(f"\nğŸ“Š å»ºè­°è¨“ç·´åƒæ•¸:")
            print(f"   --num_pos {suggested_pos}")
            print(f"   --num_neg {suggested_neg}")
        else:
            print(f"\nâš ï¸  å»ºè­°è‡³å°‘æ”¶é›† 200 å¼µæ­£æ¨£æœ¬å½±åƒï¼ˆç•¶å‰: {self.stats['positive_images']}ï¼‰")

        print()

    def collect_from_video(self, video_path, output_type="positive", 
                          frame_interval=30, max_frames=100):
        """
        å¾è¦–é »ä¸­æ”¶é›†å½±åƒ

        Args:
            video_path (str): è¦–é »æª”æ¡ˆè·¯å¾‘
            output_type (str): è¼¸å‡ºé¡å‹ ("positive" æˆ– "negative")
            frame_interval (int): æ“·å–å¹€é–“éš”
            max_frames (int): æœ€å¤§æ“·å–å¹€æ•¸
        """
        video_path = Path(video_path)
        if not video_path.exists():
            raise FileNotFoundError(f"è¦–é »æª”æ¡ˆä¸å­˜åœ¨: {video_path}")

        cap = cv2.VideoCapture(str(video_path))

        if not cap.isOpened():
            raise ValueError(f"ç„¡æ³•é–‹å•Ÿè¦–é »æª”æ¡ˆ: {video_path}")

        try:
            # ç²å–è¦–é »è³‡è¨Š
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration = frame_count / fps if fps > 0 else 0
            
            print(f"è¦–é »è³‡è¨Š: {frame_count} å¹€, {fps:.2f} FPS, {duration:.2f} ç§’")

            output_dir = self.positive_dir if output_type == "positive" else self.negative_dir
            video_name = video_path.stem

            current_frame = 0
            saved_count = 0

            print(f"å¾è¦–é »æ”¶é›†{output_type}æ¨£æœ¬: {video_path}")
            print(f"è¼¸å‡ºç›®éŒ„: {output_dir}")

            while True:
                ret, frame = cap.read()
                if not ret or saved_count >= max_frames:
                    break

                if current_frame % frame_interval == 0:
                    # ä¿å­˜å¹€
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
                    filename = f"{video_name}_{timestamp}_{saved_count:04d}.jpg"
                    filepath = output_dir / filename

                    # ä½¿ç”¨é«˜è³ªé‡åƒæ•¸ä¿å­˜å½±åƒ
                    success = cv2.imwrite(str(filepath), frame, [cv2.IMWRITE_JPEG_QUALITY, 95])
                    
                    if success:
                        saved_count += 1
                        print(f"ä¿å­˜: {filename}")
                    else:
                        print(f"ä¿å­˜å¤±æ•—: {filename}")

                current_frame += 1

        finally:
            cap.release()

        print(f"âœ“ å¾è¦–é »ä¸­æ”¶é›†äº† {saved_count} å¼µå½±åƒ")
        self.update_stats()

    def collect_from_camera(self, output_type="positive", duration=60):
        """
        å¾æ”å½±æ©Ÿå³æ™‚æ”¶é›†å½±åƒ

        Args:
            output_type (str): è¼¸å‡ºé¡å‹ ("positive" æˆ– "negative")
            duration (int): æ”¶é›†æŒçºŒæ™‚é–“ï¼ˆç§’ï¼‰
        """
        cap = cv2.VideoCapture(0)

        if not cap.isOpened():
            # å˜—è©¦å…¶ä»–æ”å½±æ©Ÿç´¢å¼•
            for i in range(1, 4):
                cap = cv2.VideoCapture(i)
                if cap.isOpened():
                    print(f"ä½¿ç”¨æ”å½±æ©Ÿç´¢å¼•: {i}")
                    break
            else:
                raise ValueError("ç„¡æ³•é–‹å•Ÿä»»ä½•æ”å½±æ©Ÿ")

        # è¨­ç½®æ”å½±æ©Ÿåƒæ•¸
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

        output_dir = self.positive_dir if output_type == "positive" else self.negative_dir

        print(f"é–‹å§‹å¾æ”å½±æ©Ÿæ”¶é›†{output_type}æ¨£æœ¬")
        print(f"æŒçºŒæ™‚é–“: {duration}ç§’")
        print("æŒ‰ 's' ä¿å­˜ç•¶å‰å¹€, æŒ‰ 'q' é€€å‡º")

        start_time = datetime.now()
        saved_count = 0

        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    print("ç„¡æ³•è®€å–æ”å½±æ©Ÿç•«é¢")
                    break

                # é¡¯ç¤ºå¹€
                display_frame = frame.copy()
                
                # æ·»åŠ è³‡è¨Šæ–‡å­—
                info_lines = [
                    f"Type: {output_type}",
                    f"Saved: {saved_count}",
                    "Press 's' to save, 'q' to quit"
                ]
                
                for i, line in enumerate(info_lines):
                    y_pos = 30 + i * 40
                    cv2.putText(display_frame, line, (10, y_pos),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

                cv2.imshow('Data Collection', display_frame)

                key = cv2.waitKey(1) & 0xFF
                if key == ord('s'):
                    # ä¿å­˜ç•¶å‰å¹€
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
                    filename = f"camera_{output_type}_{timestamp}_{saved_count:04d}.jpg"
                    filepath = output_dir / filename

                    success = cv2.imwrite(str(filepath), frame, [cv2.IMWRITE_JPEG_QUALITY, 95])
                    if success:
                        saved_count += 1
                        print(f"ä¿å­˜: {filename}")
                    else:
                        print(f"ä¿å­˜å¤±æ•—: {filename}")

                elif key == ord('q'):
                    break

                # æª¢æŸ¥æ™‚é–“é™åˆ¶
                if (datetime.now() - start_time).seconds >= duration:
                    print(f"é”åˆ°æ™‚é–“é™åˆ¶ {duration} ç§’")
                    break

        except KeyboardInterrupt:
            print("\nç”¨æˆ¶ä¸­æ–·æ”¶é›†")
        finally:
            cap.release()
            cv2.destroyAllWindows()

        print(f"âœ“ å¾æ”å½±æ©Ÿæ”¶é›†äº† {saved_count} å¼µå½±åƒ")
        self.update_stats()

    def import_images(self, source_dir, output_type="positive"):
        """
        å¾ç›®éŒ„å°å…¥å½±åƒ

        Args:
            source_dir (str): ä¾†æºç›®éŒ„
            output_type (str): è¼¸å‡ºé¡å‹ ("positive" æˆ– "negative")
        """
        source_path = Path(source_dir)
        output_dir = self.positive_dir if output_type == "positive" else self.negative_dir

        if not source_path.exists():
            raise ValueError(f"ä¾†æºç›®éŒ„ä¸å­˜åœ¨: {source_dir}")

        # æ”¯æ´çš„å½±åƒæ ¼å¼
        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']

        imported_count = 0

        for image_path in source_path.iterdir():
            if image_path.suffix.lower() in image_extensions:
                # è¤‡è£½æª”æ¡ˆ
                dest_path = output_dir / image_path.name
                shutil.copy2(image_path, dest_path)
                imported_count += 1
                print(f"å°å…¥: {image_path.name}")

        print(f"âœ“ å°å…¥äº† {imported_count} å¼µ{output_type}å½±åƒ")
        self.update_stats()

    def create_annotation_template(self, image_name):
        """
        ç‚ºå½±åƒå‰µå»ºæ¨™è¨»æ¨¡æ¿ï¼ˆYOLOæ ¼å¼ï¼‰

        Args:
            image_name (str): å½±åƒæª”æ¡ˆåç¨±
        """
        # å–å¾—å½±åƒè·¯å¾‘
        image_path = self.positive_dir / image_name
        if not image_path.exists():
            print(f"æ‰¾ä¸åˆ°å½±åƒ: {image_path}")
            return

        # å‰µå»ºæ¨™è¨»æª”æ¡ˆ
        annotation_name = image_path.stem + ".txt"
        annotation_path = self.annotations_dir / annotation_name

        # è®€å–å½±åƒå°ºå¯¸
        image = cv2.imread(str(image_path))
        if image is None:
            print(f"ç„¡æ³•è®€å–å½±åƒ: {image_path}")
            return
            
        height, width = image.shape[:2]

        # å‰µå»ºç©ºæ¨™è¨»æª”æ¡ˆï¼ˆYOLOæ ¼å¼è¨»è§£ï¼‰
        with open(annotation_path, 'w', encoding='utf-8') as f:
            f.write("# YOLOæ ¼å¼æ¨™è¨»æª”æ¡ˆ - æ ¡åœ’æ»‘æ¿è»Šåµæ¸¬\n")
            f.write("# æ ¼å¼: class_id x_center y_center width height\n")
            f.write("# æ‰€æœ‰åº§æ¨™éƒ½æ˜¯ç›¸å°æ–¼å½±åƒå°ºå¯¸çš„æ¯”ä¾‹ (0.0-1.0)\n")
            f.write(f"# å½±åƒå°ºå¯¸: {width}x{height}\n")
            f.write("# æ»‘æ¿è»Šé¡åˆ¥ID: 0\n")
            f.write("#\n")
            f.write("# ç¯„ä¾‹: 0 0.5 0.5 0.3 0.4\n")
            f.write("# (è¡¨ç¤ºåœ¨å½±åƒä¸­å¿ƒä½ç½®ï¼Œå¯¬30%é«˜40%çš„æ»‘æ¿è»Š)\n")
            f.write("#\n")
            f.write("# è«‹åˆªé™¤è¨»è§£è¡Œä¸¦æ·»åŠ å¯¦éš›æ¨™è¨»\n")

        print(f"âœ“ å‰µå»ºYOLOæ ¼å¼æ¨™è¨»æ¨¡æ¿: {annotation_path}")
        print(f"è«‹ä½¿ç”¨LabelImgï¼ˆYOLOæ¨¡å¼ï¼‰æˆ–æ‰‹å‹•ç·¨è¼¯æ­¤æª”æ¡ˆæ·»åŠ æ¨™è¨»")

    def create_classes_file(self):
        """
        å‰µå»ºé¡åˆ¥å®šç¾©æª”æ¡ˆ
        """
        classes_file = self.data_dir / "classes.txt"
        
        # å®šç¾©æ»‘æ¿è»Šæª¢æ¸¬çš„é¡åˆ¥
        classes = ["scooter"]
        
        with open(classes_file, 'w', encoding='utf-8') as f:
            for class_name in classes:
                f.write(f"{class_name}\n")
        
        print(f"âœ“ å‰µå»ºé¡åˆ¥æª”æ¡ˆ: {classes_file}")
        return classes_file

    def convert_yolo_to_haar_format(self):
        """
        å°‡YOLOæ ¼å¼æ¨™è¨»è½‰æ›ç‚ºHaar Cascadeè¨“ç·´æ ¼å¼
        """
        print("è½‰æ›YOLOæ ¼å¼æ¨™è¨»ç‚ºHaar Cascadeè¨“ç·´æ ¼å¼...")
        
        # æ”¶é›†æ‰€æœ‰æ­£æ¨£æœ¬å½±åƒ
        positive_images = []
        image_patterns = ["*.jpg", "*.png", "*.jpeg", "*.JPG", "*.PNG", "*.JPEG"]
        
        for pattern in image_patterns:
            positive_images.extend(list(self.positive_dir.glob(pattern)))
        
        haar_annotations = []
        
        for image_path in positive_images:
            annotation_path = self.annotations_dir / f"{image_path.stem}.txt"
            
            if annotation_path.exists():
                try:
                    # è®€å–å½±åƒå°ºå¯¸
                    image = cv2.imread(str(image_path))
                    if image is None:
                        continue
                    height, width = image.shape[:2];
                    
                    # è®€å–YOLOæ¨™è¨»
                    with open(annotation_path, 'r', encoding='utf-8') as f:
                        lines = f.readlines();
                    
                    objects = [];
                    for line in lines:
                        line = line.strip();
                        if line and not line.startswith('#'):
                            parts = line.split();
                            if len(parts) >= 5:
                                try:
                                    class_id, x_center, y_center, w, h = map(float, parts[:5]);
                                    
                                    # è½‰æ›YOLOåº§æ¨™åˆ°çµ•å°åƒç´ åº§æ¨™
                                    x = int((x_center - w/2) * width);
                                    y = int((y_center - h/2) * height);
                                    w_abs = int(w * width);
                                    h_abs = int(h * height);
                                    
                                    # ç¢ºä¿åº§æ¨™åœ¨æœ‰æ•ˆç¯„åœå…§
                                    x = max(0, min(x, width - 1));
                                    y = max(0, min(y, height - 1));
                                    w_abs = max(1, min(w_abs, width - x));
                                    h_abs = max(1, min(h_abs, height - y));
                                    
                                    objects.append(f"{x} {y} {w_abs} {h_abs}");
                                    
                                except ValueError:
                                    continue;
                    
                    if objects:
                        # ç›¸å°è·¯å¾‘ï¼ˆå¾å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼‰
                        rel_path = image_path.relative_to(self.project_dir);
                        line_content = f"{rel_path} {len(objects)} " + " ".join(objects);
                        haar_annotations.append(line_content);
                        
                except Exception as e:
                    print(f"è™•ç†æª”æ¡ˆæ™‚å‡ºéŒ¯ {image_path}: {e}");
                    continue;
        
        return haar_annotations;

    def create_positive_samples_list(self):
        """
        å‰µå»ºæ­£æ¨£æœ¬åˆ—è¡¨æª”æ¡ˆï¼ˆHaar Cascade è¨“ç·´ç”¨ï¼‰
        """
        positive_list_file = self.data_dir / "positive_samples.txt"
        
        # è½‰æ›YOLOæ¨™è¨»ç‚ºHaaræ ¼å¼
        haar_annotations = self.convert_yolo_to_haar_format();
        
        with open(positive_list_file, 'w', encoding='utf-8') as f:
            for annotation in haar_annotations:
                f.write(f"{annotation}\n");
        
        print(f"âœ“ å‰µå»ºæ­£æ¨£æœ¬åˆ—è¡¨: {positive_list_file}");
        print(f"  åŒ…å« {len(haar_annotations)} å€‹æœ‰æ•ˆæ¨™è¨»");
        return positive_list_file;

    def create_negative_samples_list(self):
        """
        å‰µå»ºè² æ¨£æœ¬åˆ—è¡¨æª”æ¡ˆï¼ˆHaar Cascade è¨“ç·´ç”¨ï¼‰
        """
        negative_list_file = self.data_dir / "negative_samples.txt"
        
        # æ”¶é›†æ‰€æœ‰è² æ¨£æœ¬å½±åƒ
        negative_images = []
        image_patterns = ["*.jpg", "*.png", "*.jpeg", "*.JPG", "*.PNG", "*.JPEG"]
        
        for pattern in image_patterns:
            negative_images.extend(list(self.negative_dir.glob(pattern)))
        
        with open(negative_list_file, 'w', encoding='utf-8') as f:
            for image_path in negative_images:
                # ç›¸å°è·¯å¾‘ï¼ˆå¾å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼‰
                rel_path = image_path.relative_to(self.project_dir)
                f.write(f"{rel_path}\n")
        
        print(f"âœ“ å‰µå»ºè² æ¨£æœ¬åˆ—è¡¨: {negative_list_file}")
        print(f"  åŒ…å« {len(negative_images)} å¼µè² æ¨£æœ¬å½±åƒ")
        return negative_list_file

    def validate_training_data(self):
        """
        é©—è­‰è¨“ç·´è³‡æ–™çš„å“è³ªå’Œå®Œæ•´æ€§
        """
        print("=== é©—è­‰è¨“ç·´è³‡æ–™ ===")
        
        # åŸºæœ¬çµ±è¨ˆ
        self.update_stats()
        print(f"æ­£æ¨£æœ¬å½±åƒ: {self.stats['positive_images']}")
        print(f"è² æ¨£æœ¬å½±åƒ: {self.stats['negative_images']}")
        print(f"æ¨™è¨»æª”æ¡ˆ: {self.stats['annotations']}")
        
        # æª¢æŸ¥æœ€ä½è¦æ±‚
        issues = []
        if self.stats['positive_images'] < 100:
            issues.append(f"æ­£æ¨£æœ¬æ•¸é‡ä¸è¶³ï¼ˆå»ºè­°è‡³å°‘200å¼µï¼Œç•¶å‰{self.stats['positive_images']}å¼µï¼‰")
        
        if self.stats['negative_images'] < 500:
            issues.append(f"è² æ¨£æœ¬æ•¸é‡ä¸è¶³ï¼ˆå»ºè­°è‡³å°‘1000å¼µï¼Œç•¶å‰{self.stats['negative_images']}å¼µï¼‰")
        
        if self.stats['annotations'] < self.stats['positive_images'] * 0.8:
            issues.append(f"æ¨™è¨»æª”æ¡ˆéå°‘ï¼ˆæ‡‰è©²æ¥è¿‘æ­£æ¨£æœ¬æ•¸é‡ï¼‰")
        
        # é©—è­‰æ¨™è¨»å“è³ª
        valid_annotations, invalid_files = self.validate_annotations()
        
        if invalid_files:
            issues.extend(invalid_files[:5])  # åªé¡¯ç¤ºå‰5å€‹éŒ¯èª¤
        
        # æª¢æŸ¥å½±åƒå“è³ª
        quality_issues = self.check_image_quality()
        if quality_issues:
            issues.extend(quality_issues)
        
        # å ±å‘Šçµæœ
        if not issues:
            print("âœ… è¨“ç·´è³‡æ–™é©—è­‰é€šéï¼")
            print("\nå»ºè­°çš„è¨“ç·´å‘½ä»¤:")
            suggested_pos = min(int(self.stats['positive_images'] * 0.9), 1800)
            suggested_neg = min(int(self.stats['negative_images'] * 0.9), 3600)
            print(f"python train_cascade.py --num_pos {suggested_pos} --num_neg {suggested_neg}")
            return True
        else:
            print("âŒ ç™¼ç¾ä»¥ä¸‹å•é¡Œ:")
            for i, issue in enumerate(issues[:10], 1):
                print(f"  {i}. {issue}")
            if len(issues) > 10:
                print(f"  ... é‚„æœ‰ {len(issues)-10} å€‹å•é¡Œ")
            return False

    def check_image_quality(self):
        """
        æª¢æŸ¥å½±åƒå“è³ª
        """
        issues = []
        
        # æª¢æŸ¥æ­£æ¨£æœ¬å½±åƒ
        image_patterns = ["*.jpg", "*.png", "*.jpeg", "*.JPG", "*.PNG", "*.JPEG"]
        positive_images = []
        
        for pattern in image_patterns:
            positive_images.extend(list(self.positive_dir.glob(pattern)))
        
        small_images = 0
        corrupted_images = 0
        
        for image_path in positive_images[:50]:  # åªæª¢æŸ¥å‰50å¼µ
            try:
                image = cv2.imread(str(image_path))
                if image is None:
                    corrupted_images += 1
                    continue
                    
                height, width = image.shape[:2]
                if width < 100 or height < 100:
                    small_images += 1
                    
            except Exception:
                corrupted_images += 1
        
        if small_images > 0:
            issues.append(f"ç™¼ç¾ {small_images} å¼µå°ºå¯¸éå°çš„å½±åƒï¼ˆå»ºè­°è‡³å°‘100x100åƒç´ ï¼‰")
        
        if corrupted_images > 0:
            issues.append(f"ç™¼ç¾ {corrupted_images} å¼µæå£çš„å½±åƒæª”æ¡ˆ")
        
        return issues

    def prepare_haar_training_data(self):
        """
        æº–å‚™ Haar Cascade è¨“ç·´è³‡æ–™
        """
        print("=== æº–å‚™ Haar Cascade è¨“ç·´è³‡æ–™ ===")
        
        # é©—è­‰è³‡æ–™å“è³ª
        if not self.validate_training_data():
            print("\nâŒ è³‡æ–™é©—è­‰å¤±æ•—ï¼Œè«‹å…ˆä¿®æ­£ä¸Šè¿°å•é¡Œ")
            return False
        
        # å‰µå»ºæ¨£æœ¬åˆ—è¡¨
        positive_file = self.create_positive_samples_list()
        negative_file = self.create_negative_samples_list()
        
        # å‰µå»ºå¿…è¦ç›®éŒ„
        vec_dir = self.data_dir / "vec"
        vec_dir.mkdir(exist_ok=True)
        
        cascade_dir = self.data_dir / "cascade"
        cascade_dir.mkdir(exist_ok=True)
        
        # è¨ˆç®—å»ºè­°åƒæ•¸
        suggested_pos = min(int(self.stats['positive_images'] * 0.9), 1800)
        suggested_neg = min(int(self.stats['negative_images'] * 0.9), 3600)
        
        print(f"\n=== Haar Cascade è¨“ç·´æŒ‡å— ===")
        print(f"ğŸ“ è³‡æ–™ç›®éŒ„å·²æº–å‚™å®Œæˆ")
        print(f"   æ­£æ¨£æœ¬åˆ—è¡¨: {positive_file}")
        print(f"   è² æ¨£æœ¬åˆ—è¡¨: {negative_file}")
        print(f"   å‘é‡æª”æ¡ˆç›®éŒ„: {vec_dir}")
        print(f"   è¨“ç·´è¼¸å‡ºç›®éŒ„: {cascade_dir}")
        
        print(f"\nğŸ”§ å»ºè­°çš„è¨“ç·´å‘½ä»¤:")
        print(f"1. å‰µå»ºæ¨£æœ¬å‘é‡æª”æ¡ˆ:")
        print(f"   opencv_createsamples -info {positive_file} -bg {negative_file}")
        print(f"   -vec {vec_dir}/samples.vec -w 24 -h 24")
        
        print(f"\n2. è¨“ç·´åˆ†é¡å™¨:")
        print(f"   opencv_traincascade -data {cascade_dir}")
        print(f"   -vec {vec_dir}/samples.vec -bg {negative_file}")
        print(f"   -numPos {suggested_pos} -numNeg {suggested_neg}")
        print(f"   -w 24 -h 24 -numStages 20")
        
        print(f"\nğŸ“Š è¨“ç·´è³‡æ–™çµ±è¨ˆ:")
        print(f"   å¯ç”¨æ­£æ¨£æœ¬: {self.stats['positive_images']}")
        print(f"   å¯ç”¨è² æ¨£æœ¬: {self.stats['negative_images']}")
        print(f"   å»ºè­°ä½¿ç”¨æ­£æ¨£æœ¬: {suggested_pos}")
        print(f"   å»ºè­°ä½¿ç”¨è² æ¨£æœ¬: {suggested_neg}")
        
        print(f"\nâš ï¸  é‡è¦æé†’:")
        print(f"   - ç¢ºä¿å·²å®‰è£ OpenCV å‘½ä»¤åˆ—å·¥å…·")
        print(f"   - è¨“ç·´éç¨‹å¯èƒ½éœ€è¦æ•¸å°æ™‚")
        print(f"   - å»ºè­°å…ˆç”¨è¼ƒå°‘çš„æ¨£æœ¬æ¸¬è©¦")
        print(f"   - è¨“ç·´å®Œæˆå¾Œæ¨¡å‹å°‡ä¿å­˜åœ¨ {self.trained_model_dir}")
        
        return positive_file, negative_file

    def launch_labelimg(self, image_dir=None):
        """
        å•Ÿå‹•LabelImgæ¨™è¨»å·¥å…·

        Args:
            image_dir (str): è¦æ¨™è¨»çš„å½±åƒç›®éŒ„ï¼Œé è¨­ç‚ºæ­£æ¨£æœ¬ç›®éŒ„
        """
        if image_dir is None:
            image_dir = str(self.positive_dir)

        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        Path(image_dir).mkdir(parents=True, exist_ok=True)
        self.annotations_dir.mkdir(parents=True, exist_ok=True)
        
        # å‰µå»ºé¡åˆ¥æª”æ¡ˆ
        classes_file = self.create_classes_file()

        try:
            import subprocess
            import sys
            
            # å˜—è©¦ä¸åŒçš„å•Ÿå‹•æ–¹å¼
            commands = [
                ["labelImg", image_dir],
                ["python", "-m", "labelImg", image_dir],
                [sys.executable, "-m", "labelImg", image_dir]
            ]
            
            for i, cmd in enumerate(commands):
                try:
                    print(f"å˜—è©¦å•Ÿå‹•æ–¹å¼ {i+1}: {' '.join(cmd)}")
                    subprocess.Popen(cmd, cwd=str(self.project_dir))
                    print(f"âœ“ å•Ÿå‹•LabelImgæ¨™è¨»å·¥å…·")
                    print(f"å½±åƒç›®éŒ„: {image_dir}")
                    print(f"é¡åˆ¥æª”æ¡ˆ: {classes_file}")
                    print(f"æ¨™è¨»ç›®éŒ„: {self.annotations_dir}")
                    print("\nğŸ“ LabelImg è¨­å®šæŒ‡å—:")
                    print("1. åœ¨LabelImgä¸­ï¼Œé»æ“Š 'View' -> 'Auto Save mode' å•Ÿç”¨è‡ªå‹•å„²å­˜")
                    print("2. é»æ“Šå·¦å´çš„ 'PascalVOC' æŒ‰éˆ•ï¼Œåˆ‡æ›åˆ° 'YOLO' æ ¼å¼")
                    print("3. é»æ“Š 'Change Save Dir' è¨­å®šæ¨™è¨»å„²å­˜ç›®éŒ„ç‚º data/annotations")
                    print("4. é»æ“Š 'Change default saved annotation folder' ç¢ºèªè¨­å®š")
                    print("5. é–‹å§‹æ¨™è¨»æ»‘æ¿è»Šç‰©ä»¶ï¼ˆé¡åˆ¥ï¼šscooterï¼‰")
                    print("\nğŸ’¡ æ¨™è¨»æŠ€å·§:")
                    print("- ç›¡é‡æ¡†ä½å®Œæ•´çš„æ»‘æ¿è»Š")
                    print("- åŒ…å«è»Šè¼ªã€è¸æ¿å’ŒæŠŠæ‰‹")
                    print("- é¿å…æ¡†ä½éå¤šèƒŒæ™¯")
                    print("- ç¢ºä¿æ¯å¼µå½±åƒéƒ½æœ‰å°æ‡‰çš„ .txt æ¨™è¨»æª”æ¡ˆ")
                    return
                except (FileNotFoundError, PermissionError) as e:
                    print(f"å•Ÿå‹•å¤±æ•—: {e}")
                    continue
                    
            raise FileNotFoundError("ç„¡æ³•æ‰¾åˆ°æˆ–å•Ÿå‹• labelImg")
            
        except Exception as e:
            print("âœ— æ‰¾ä¸åˆ°LabelImgå·¥å…·æˆ–å•Ÿå‹•å¤±æ•—")
            print("\nğŸ“¦ å®‰è£LabelImg:")
            print("pip install labelImg")
            print("æˆ–")
            print("conda install labelimg")
            print(f"\nâŒ éŒ¯èª¤è©³æƒ…: {e}")
            
            # æä¾›æ‰‹å‹•æ¨™è¨»çš„èªªæ˜
            print("\n=== YOLO æ‰‹å‹•æ¨™è¨»æ ¼å¼ ===")
            print(f"ğŸ“ å½±åƒæª”æ¡ˆä½ç½®: {image_dir}")
            print(f"ğŸ“ æ¨™è¨»æª”æ¡ˆä½ç½®: {self.annotations_dir}")
            print(f"ğŸ“„ é¡åˆ¥æª”æ¡ˆä½ç½®: {classes_file}")
            print("ğŸ“ æ¨™è¨»æ ¼å¼: class_id x_center y_center width height")
            print("   - class_id: 0 (æ»‘æ¿è»Š)")
            print("   - æ‰€æœ‰åº§æ¨™éƒ½æ˜¯ç›¸å°æ¯”ä¾‹ (0.0-1.0)")
            print("   - ç¯„ä¾‹: 0 0.5 0.5 0.3 0.4")
            print("âœ… å®Œæˆæ¨™è¨»å¾ŒåŸ·è¡Œ: python data_collection.py --action validate")

    def validate_annotations(self):
        """
        é©—è­‰æ¨™è¨»æª”æ¡ˆçš„æœ‰æ•ˆæ€§ï¼ˆYOLOæ ¼å¼ï¼‰
        """
        print("é©—è­‰ YOLO æ ¼å¼æ¨™è¨»æª”æ¡ˆ...")

        valid_count = 0
        invalid_files = []

        annotation_files = list(self.annotations_dir.glob("*.txt"))
        
        if not annotation_files:
            print("æœªæ‰¾åˆ°ä»»ä½•æ¨™è¨»æª”æ¡ˆ")
            return 0, []

        for annotation_file in annotation_files:
            try:
                with open(annotation_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()

                valid_annotations = 0
                for line_num, line in enumerate(lines, 1):
                    line = line.strip()
                    if line and not line.startswith('#'):
                        parts = line.split()
                        if len(parts) >= 5:
                            try:
                                # æª¢æŸ¥YOLOæ ¼å¼
                                class_id = int(parts[0])
                                x, y, w, h = map(float, parts[1:5])

                                # æª¢æŸ¥åº§æ¨™ç¯„åœ
                                if (0 <= x <= 1 and 0 <= y <= 1 and 
                                    0 < w <= 1 and 0 < h <= 1 and
                                    class_id == 0):  # åªæ¥å—æ»‘æ¿è»Šé¡åˆ¥
                                    valid_annotations += 1
                                else:
                                    invalid_files.append(f"{annotation_file.name}:è¡Œ{line_num} - åº§æ¨™è¶…å‡ºç¯„åœæˆ–é¡åˆ¥éŒ¯èª¤")
                            except ValueError as e:
                                invalid_files.append(f"{annotation_file.name}:è¡Œ{line_num} - æ•¸å€¼æ ¼å¼éŒ¯èª¤: {e}")
                        else:
                            invalid_files.append(f"{annotation_file.name}:è¡Œ{line_num} - YOLOæ ¼å¼ä¸æ­£ç¢º")

                if valid_annotations > 0:
                    valid_count += 1
                elif annotation_file.stat().st_size > 0:  # æª”æ¡ˆä¸ç‚ºç©ºä½†æ²’æœ‰æœ‰æ•ˆæ¨™è¨»
                    invalid_files.append(f"{annotation_file.name} - ç„¡æœ‰æ•ˆYOLOæ¨™è¨»")

            except Exception as e:
                invalid_files.append(f"{annotation_file.name}: {e}")

        print(f"âœ“ æœ‰æ•ˆæ¨™è¨»æª”æ¡ˆ: {valid_count}/{len(annotation_files)}")
        if invalid_files:
            print(f"âœ— ç™¼ç¾å•é¡Œ: {len(invalid_files)}")
            for file in invalid_files[:10]:  # åªé¡¯ç¤ºå‰10å€‹
                print(f"  - {file}")
            if len(invalid_files) > 10:
                print(f"  ... é‚„æœ‰ {len(invalid_files)-10} å€‹å•é¡Œ")

        return valid_count, invalid_files

def main():
    parser = argparse.ArgumentParser(
        description='æ ¡åœ’æ»‘æ¿è»Šåµæ¸¬ - è³‡æ–™æ”¶é›†å·¥å…· v1.0',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹ç”¨æ³•:
  æŸ¥çœ‹è³‡æ–™çµ±è¨ˆ:     python data_collection.py --action stats
  æ”å½±æ©Ÿæ”¶é›†è³‡æ–™:   python data_collection.py --action camera --type positive --duration 120
  å¾è¦–é »æ”¶é›†:       python data_collection.py --action video --source video.mp4 --type positive
  åŒ¯å…¥å½±åƒ:         python data_collection.py --action import --source /path/to/images --type positive
  å•Ÿå‹•æ¨™è¨»å·¥å…·:     python data_collection.py --action annotate
  é©—è­‰æ¨™è¨»:         python data_collection.py --action validate
  æº–å‚™è¨“ç·´è³‡æ–™:     python data_collection.py --action prepare_haar
  é©—è­‰è¨“ç·´è³‡æ–™:     python data_collection.py --action validate_training

æ›´å¤šè³‡è¨Šè«‹åƒè€ƒ: README.md
        """
    )
    
    parser.add_argument('--project_dir', default='./', help='å°ˆæ¡ˆç›®éŒ„è·¯å¾‘ (é è¨­: ./)')
    parser.add_argument('--action', 
                       choices=['stats', 'camera', 'video', 'import', 'annotate', 
                               'validate', 'prepare_haar', 'validate_training'],
                       required=True, 
                       help='åŸ·è¡Œå‹•ä½œ')
    parser.add_argument('--type', choices=['positive', 'negative'], default='positive',
                       help='è³‡æ–™é¡å‹ (é è¨­: positive)')
    parser.add_argument('--source', help='ä¾†æºæª”æ¡ˆæˆ–ç›®éŒ„')
    parser.add_argument('--duration', type=int, default=60, help='æ”å½±æ©Ÿæ”¶é›†æŒçºŒæ™‚é–“ï¼ˆç§’ï¼Œé è¨­: 60ï¼‰')
    parser.add_argument('--interval', type=int, default=30, help='è¦–é »å¹€æ“·å–é–“éš” (é è¨­: 30)')
    parser.add_argument('--max_frames', type=int, default=100, help='æœ€å¤§æ“·å–å¹€æ•¸ (é è¨­: 100)')

    args = parser.parse_args()

    try:
        collector = DataCollector(args.project_dir)

        if args.action == 'stats':
            collector.show_stats()

        elif args.action == 'camera':
            collector.collect_from_camera(args.type, args.duration)

        elif args.action == 'video':
            if not args.source:
                raise ValueError("è¦–é »æ”¶é›†éœ€è¦æŒ‡å®š --source åƒæ•¸")
            collector.collect_from_video(args.source, args.type, 
                                       args.interval, args.max_frames)

        elif args.action == 'import':
            if not args.source:
                raise ValueError("å°å…¥å½±åƒéœ€è¦æŒ‡å®š --source åƒæ•¸")
            collector.import_images(args.source, args.type)

        elif args.action == 'annotate':
            collector.launch_labelimg()

        elif args.action == 'validate':
            collector.validate_annotations()

        elif args.action == 'prepare_haar':
            collector.prepare_haar_training_data()
            
        elif args.action == 'validate_training':
            collector.validate_training_data()

    except KeyboardInterrupt:
        print("\nç¨‹åºè¢«ç”¨æˆ¶ä¸­æ–·")
        return 0
    except Exception as e:
        print(f"âœ— éŒ¯èª¤: {e}")
        import traceback
        print("è©³ç´°éŒ¯èª¤è³‡è¨Š:")
        traceback.print_exc()
        return 1

    return 0

if __name__ == "__main__":
    exit(main())
